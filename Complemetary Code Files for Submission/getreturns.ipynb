{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from conditionalAssetPricingLogMarginalLikelihoodTauClass import Model\n",
    "\n",
    "# === Step 1: Setup ===\n",
    "homeDir = r'C:\\Users\\Tor Osted\\OneDrive\\Dokumenter\\GitHub\\speciale_repo\\Complemetary Code Files for Submission\\\\'\n",
    "dataDir = homeDir + r'Data\\\\'\n",
    "\n",
    "directory_name_prefix = homeDir + 'conditionalTauDMN0F14M13s'\n",
    "\n",
    "# === Step 2: Choose number of predictors to use ===\n",
    "n_predictors_to_use = 2  # ðŸ”§ Set this to anything between 1 and 13\n",
    "assert 1 <= n_predictors_to_use <= 13, \"You must choose between 1 and 13 predictors\"\n",
    "\n",
    "# === Step 3: Load test assets (returns) ===\n",
    "returns = pd.read_excel(dataDir + 'Returns.xlsx', sheet_name=\"Industry_returns\")\n",
    "returns = returns.iloc[:-1]  # remove first row\n",
    "\n",
    "returns = returns.drop(columns=['Grand Total'])  # remove Date column\n",
    "for col in returns.columns:\n",
    "    returns[col] = returns[col] * 100\n",
    "# === Step 4: Load and clean factors ===\n",
    "factors = pd.read_csv(dataDir + 'factors-20.csv')\n",
    "factors = factors.drop(columns=['MKTRF','SMB*','MKT','CON','IA', 'ROE', 'ME'])  # remove redundant/duplicated\n",
    "factorsNames = factors.columns.drop('Date')\n",
    "for col in factors.columns:\n",
    "   if col != 'Date':\n",
    "        factors[col] = factors[col] * 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(returns.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.drop(columns=\"Row Labels\", inplace=True)\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 5: Load and clean predictors ===\n",
    "predictors = pd.read_csv(dataDir + 'Z - 197706.csv')\n",
    "if 'Unnamed: 0' in predictors.columns:\n",
    "    predictors = predictors.drop(columns='Unnamed: 0')\n",
    "\n",
    "# Define full predictor index list\n",
    "full_predictor_list = predictors.columns.drop('Date')\n",
    "significantPredictors = np.arange(n_predictors_to_use)\n",
    "predictorsNames = full_predictor_list[significantPredictors]\n",
    "\n",
    "# Subset actual predictor data\n",
    "predictors = predictors[['Date'] + predictorsNames.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictors.describe().T[['mean', 'std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 6: Truncate all to shared sample size and index ===\n",
    "start_date = '1997-01-01'\n",
    "end_date = '2006-12-01'\n",
    "date_index = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "n = len(date_index)\n",
    "\n",
    "returns = returns.iloc[:n].copy()\n",
    "\n",
    "#returns_sim = returns_sim.iloc[:n].copy()\n",
    "\n",
    "factors = factors.iloc[:n].copy()\n",
    "predictors = predictors.iloc[:n].copy()\n",
    "# === Convert decimal returns to percent returns ===\n",
    "\n",
    "returns.index = date_index\n",
    "factors.index = date_index\n",
    "predictors.index = date_index\n",
    "\n",
    "# === Step 7: Reset index and rename for model compatibility ===\n",
    "returns_reset = returns.reset_index().rename(columns={'index': 'Date'})\n",
    "#returns_reset.drop(columns='Row Labels', inplace=True) \n",
    "\n",
    "#returns_sim_reset = returns_sim.reset_index().rename(columns={'index': 'Date'})\n",
    "\n",
    "factors_reset = factors.reset_index().rename(columns={'index': 'Date'})\n",
    "predictors_reset = predictors.reset_index().rename(columns={'index': 'Date'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Step 8: Define model parameters ===\n",
    "Tau = 1.5\n",
    "index_end_of_estimation = 118  # Half of length of returns\n",
    "\n",
    "# === Step 9: Instantiate model ===\n",
    "model = Model(rr=returns_reset,\n",
    "              ff=factors_reset,\n",
    "              zz=predictors_reset,\n",
    "              significantPredictors=significantPredictors,\n",
    "              Tau=Tau,\n",
    "              indexEndOfEstimation=index_end_of_estimation,\n",
    "              key_demean_predictors=True)\n",
    "\n",
    "# === Step 10: Run conditional BMA expected return calculation ===\n",
    "nModelsMax = pow(2, model.KMax + model.MMax)\n",
    "uniform_probs = np.ones(nModelsMax) / nModelsMax\n",
    "models_probabilities = np.concatenate([uniform_probs, uniform_probs])\n",
    "\n",
    "result = model.conditionalAssetPricingOOSTauNumba(\n",
    "    models_probabilities=models_probabilities,\n",
    "    nModelsInPrediction=0  # Use full model space\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
